{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Demo for disorganized info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests ## a library that returns information from websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to scrape\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use the request library to grab page content\n",
    "## get contents of URL and store in object called page.\n",
    "## Let's print page and see what we have.\n",
    "page = requests.get(url)\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what type of object is it?\n",
    "print(type(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We'll used BeautifulSoup to convert content into content we recognize\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prettify the print so it's easier to see the HTML tree.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## soup captures the entire page.\n",
    "## we narrow it down to capture our target section and store in object called dis\n",
    "dis = soup.find(\"section\", id=\"disorganized\")\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the labels (column headers)\n",
    "## using for loop and store in list called labels_fl\n",
    "\n",
    "labels_fl = []\n",
    "labels = dis.find(\"div\").find_all(\"span\")\n",
    "for label in labels:\n",
    "    label = label.get_text().strip(\":\")\n",
    "    labels_fl.append(label)\n",
    "\n",
    "labels_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the labels (column headers)\n",
    "## using list comprehension save in a list called labels_lc\n",
    "labels_lc = [label.get_text().strip(':') for label in labels]\n",
    "labels_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find class ceo and store in object called ceos\n",
    "ceos = dis.find_all(\"div\", class_=\"ceo\")\n",
    "ceos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the previous field gave us the entire div as one. \n",
    "## break it down so each ceo is it's own list element.\n",
    "for ceo in ceos:\n",
    "    each_ceo = ceo.find_all(\"dt\")\n",
    "    print(each_ceo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how might we capture each rank, name, annual compension and company name?\n",
    "## hint: list slicing\n",
    "for ceo in ceos:\n",
    "    each_ceo = ceo.find_all(\"dt\")\n",
    "    rank = each_ceo[0].get_text()\n",
    "    name = each_ceo[1].get_text()\n",
    "    annual_compensation = each_ceo[2].get_text()\n",
    "    company = each_ceo[3].get_text()\n",
    "    print(f\"Rank:{rank}, Name:{name}, Annual Compensation:{annual_compensation}, Company:{company}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we only printed them out. let's store in a list of dicts called ceo_dict_list\n",
    "ceo_dict_list = []\n",
    "for ceo in ceos:\n",
    "    each_ceo = ceo.find_all(\"dt\")\n",
    "    rank = each_ceo[0].get_text()\n",
    "    name = each_ceo[1].get_text()\n",
    "    annual_compensation = each_ceo[2].get_text()\n",
    "    company = each_ceo[3].get_text()\n",
    "    ceo_dict = {\"Rank\": rank, \"Name\": name, \"Company\": company, \"Annual Compensation\": annual_compensation}\n",
    "    ceo_dict_list.append(ceo_dict)\n",
    "ceo_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use pandas to write to csv file\n",
    "filename = \"disorganized.csv\" ## what are file name is\n",
    "df = pd.DataFrame(ceo_dict_list) ## we turn our list of dicts into a dataframe which we're call df\n",
    "df.to_csv(filename, encoding='utf-8', index=False) ## export to csv as utf-8 coding (it just has to be this)\n",
    "\n",
    "print(f\"{filename} is in your project folder!\") ## a print out that tells us the file is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
