{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja871rAui_Da"
   },
   "source": [
    "# Scraping Files from Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwHrS-KJi_Dg"
   },
   "source": [
    "### You need to create a data set that tracks how many companies the <a href=\"https://www.sec.gov/litigation/suspensions.shtml\">SEC suspended</a> between 2019 and 1999. You find the data at:\n",
    "\n",
    "```https://www.sec.gov/litigation/suspensions.shtml```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_OAOaqLi_Dh"
   },
   "source": [
    "### We want to write a scraper that aggregates:\n",
    "\n",
    "* Date of suspension\n",
    "* Company name\n",
    "* Order\n",
    "* Release (the PDFs in the XX-YYYYY format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECK4Q7IOi_Di"
   },
   "source": [
    "# The Challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQj34GvYi_Di"
   },
   "source": [
    "### Details are actually in PDFs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfkXDlQvi_Di"
   },
   "source": [
    "# Demo downloading files from websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvf5HLGi_Dj"
   },
   "source": [
    "There are ```txt``` and ```pdf``` files on:\n",
    "\n",
    "```https://sandeepmj.github.io/scrape-example-page/pages.html```\n",
    "\n",
    "Do the following:\n",
    "\n",
    "1. Download all ```txt``` files.\n",
    "2. Download all ```pdf``` files.\n",
    "3. Download all ```txt``` files at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W1jQ2nQei_Dj"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup  ## scrape info from web pages\n",
    "import requests ## get web pages from server\n",
    "import time # time is required. we will use its sleep function\n",
    "from random import randrange # generate random numbers\n",
    "\n",
    "# from google.colab import files ## code for downloading in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cV7Mwt-Ai_Dk"
   },
   "outputs": [],
   "source": [
    "# url to scrape\n",
    "url = \"https://sandeepmj.github.io/scrape-example-page/pages.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpRuGa4V_gpp",
    "outputId": "6f22e2e0-69f5-4775-f999-7cb8a9f35343"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## request site data\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyHHqpmYi_Dk"
   },
   "source": [
    "## Turn page into soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dIkCJBH8i_Dk"
   },
   "outputs": [],
   "source": [
    "## get url and print but hard to read. will do prettify next\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z42CN1eKi_Dk"
   },
   "source": [
    "## Find all txt files in the first set of txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gUSgXcKAijB",
    "outputId": "a4c686e2-9bed-4020-ebe6-4b8c85bb7fea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>Junk Li <a href=\"\">tag 1</a></li>,\n",
       " <li>Junk Li <a href=\"\">tag 2</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>,\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>,\n",
       " <li>Junk Li <a href=\"\">tag 3</a></li>,\n",
       " <li>Junk Li <a href=\"\">tag 4</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_1.pdf\">1</a> </li>,\n",
       " <li>PDF Document <a href=\"files/pdf_2.pdf\">2</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_3.pdf\">3</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_4.pdf\">4</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_5.pdf\">5</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_6.pdf\">6</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_7.pdf\">7</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_8.pdf\">8</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_9.pdf\">9</a></li>,\n",
       " <li>PDF Document <a href=\"files/pdf_10.pdf\">10</a></li>,\n",
       " <li>Junk Li <a href=\"\">tag 5</a></li>,\n",
       " <li>Junk Li <a href=\"\">tag 6</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>,\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>,\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## too wide\n",
    "soup.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5GhvRuji_Dl",
    "outputId": "c076672d-9fbd-4981-9e8d-a44f46a1634e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul class=\"txts downloadable\">\n",
       "<p class=\"pages\">Download this first set of text documents</p>\n",
       "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       "</ul>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## save in list called txt_holder\n",
    "txt_holder = soup.find(\"ul\", class_=\"txts\")\n",
    "txt_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA0It-LoA4Vf",
    "outputId": "fff58b83-76f5-498d-c972-a32e31db42db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## type\n",
    "type(txt_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8sCo7syi_Dl"
   },
   "source": [
    "## Find all the ```a``` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BBjQWqsi_Dl",
    "outputId": "a3115042-2540-477a-d977-5aae8a63daab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find a tags\n",
    "link_a_tags = txt_holder.find_all(\"a\")\n",
    "link_a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z1uhcyKHCAw0",
    "outputId": "4db7d45f-bd39-40e3-8180-d300c7280a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find a_tags in one step\n",
    "\n",
    "a_list = soup.find(\"ul\", class_=\"txts\").find_all(\"a\")\n",
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zguzFwoACuSd"
   },
   "outputs": [],
   "source": [
    "## for loop\n",
    "links = []\n",
    "for a_tag in a_list:\n",
    "  # print(link)\n",
    "  links.append(a_tag.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPgFpi0ui_Dl",
    "outputId": "e5228d7c-57fe-46cd-ed33-898efe96d97c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/text_doc_01.txt',\n",
       " 'files/text_doc_02.txt',\n",
       " 'files/text_doc_03.txt',\n",
       " 'files/text_doc_04.txt',\n",
       " 'files/text_doc_05.txt',\n",
       " 'files/text_doc_06.txt',\n",
       " 'files/text_doc_07.txt',\n",
       " 'files/text_doc_08.txt',\n",
       " 'files/text_doc_09.txt',\n",
       " 'files/text_doc_10.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at the links\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Sv-zUhi_Dm"
   },
   "source": [
    "## What is missing from the URLs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BR4K5BkGi_Dm"
   },
   "outputs": [],
   "source": [
    "## base url\n",
    "base_url = \"https://sandeepmj.github.io/scrape-example-page/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8sgMa05i_Dm"
   },
   "source": [
    "## Create a list of the full URLs\n",
    "\n",
    "Without all the ```html```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOJEvd2ki_Dm",
    "outputId": "9bd2cee7-c353-469a-964a-30767f2a881e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/files/text_doc_01.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_02.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_03.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_04.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_05.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_06.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_07.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_08.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_09.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_10.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lc\n",
    "all_links = [base_url + link for link in links]\n",
    "all_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCqmE0y6i_Dm"
   },
   "source": [
    "## Download all the ```txt``` documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok4Wh8ucEwRc",
    "outputId": "32b43d27-3ffb-42de-aa26-7b5e806d431e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/sandeepjunnarkar/opt/anaconda3/lib/python3.9/site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zUM7ToNEi_Dn"
   },
   "outputs": [],
   "source": [
    "import wget # can put down documents, files from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "X_aUuV5ci_Dn",
    "outputId": "e878270b-fb26-47c0-e075-9ae455246d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jg/xjfmqdcj0m1bqs1d7sgv9v480000gp/T/ipykernel_57143/1828189399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mlink_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#wget.download(link) ## non-colab notebook code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## this has files.download colab command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0msnoozer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Snoozing for {snoozer} seconds before next link\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "## download with timer\n",
    "links_total = len(all_links)\n",
    "link_count = 1\n",
    "\n",
    "for link in all_links:\n",
    "  print(f\"Downloading link {link_count} of {links_total}\")\n",
    "  link_count += 1\n",
    "  wget.download(link) ## non-colab notebook code\n",
    "#   files.download(wget.download(link)) ## this has files.download colab command\n",
    "  snoozer = randrange(3, 7)\n",
    "  print(f\"Snoozing for {snoozer} seconds before next link\")\n",
    "  time.sleep(snoozer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt6eKURbi_Dn"
   },
   "source": [
    "# Find all ```pdf``` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0aipPxyi_Dn",
    "outputId": "541c3910-8773-4666-e986-f5915e657407"
   },
   "outputs": [],
   "source": [
    "## grab pdfs links\n",
    "pdf_a = soup.find(\"ul\", class_=\"pdfs\").find_all(\"a\")\n",
    "pdf_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUEScUwei_Dn"
   },
   "source": [
    "## Find all the ```a``` tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DohlMXf2i_Do",
    "outputId": "411aff21-e44a-4fd1-9cf3-05af1885138a"
   },
   "outputs": [],
   "source": [
    "## for loop store in all_pdf_links_fl\n",
    "pdf_links_fl = []\n",
    "for pdf_link in pdf_a:\n",
    "  pdf_links_fl.append(base_url + pdf_link.get(\"href\"))\n",
    "\n",
    "pdf_links_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LlMLka-Qe0x",
    "outputId": "33901316-c7a6-4536-d6eb-f0951a7966c0"
   },
   "outputs": [],
   "source": [
    "## list comprehension\n",
    "\n",
    "pdf_links = [base_url + a_tag.get(\"href\") for a_tag in pdf_a]\n",
    "pdf_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8QfQI1Qi_Do"
   },
   "source": [
    "## Download all the ```pdf``` documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "W7-meNFri_Do",
    "outputId": "9ddc916a-78e7-44ee-8772-20b9bdedb2a5"
   },
   "outputs": [],
   "source": [
    "## download with timer\n",
    "links_total = len(pdf_links)\n",
    "link_count = 1\n",
    "\n",
    "for link in pdf_links:\n",
    "  print(f\"Downloading link {link_count} of {links_total}\")\n",
    "  link_count += 1\n",
    "  #wget.download(link) ## non-colab notebook code\n",
    "  files.download(wget.download(link)) ## this has files.download colab command\n",
    "  snoozer = randrange(3, 7)\n",
    "  print(f\"Snoozing for {snoozer} seconds before next link\")\n",
    "  time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLOjF-XKi_Do"
   },
   "source": [
    "# Find all the txt files in both sets and download at one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Toth3b6ui_Dp"
   },
   "source": [
    "# Target the class ```downloadable```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6mKi4RWi_Dp",
    "outputId": "4e139249-de8a-48a6-ef38-88d17f915907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this first set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
       " </ul>,\n",
       " <ul class=\"txts downloadable\">\n",
       " <p class=\"pages\">Download this second set of text documents</p>\n",
       " <li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
       " <li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
       " <li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find all files in our soup\n",
    "docs_holder = soup.find_all(\"ul\", class_=\"txts\")\n",
    "docs_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grnOHd9di_Dp",
    "outputId": "04d7f3ae-fd8a-47d1-b8e1-7388cc7ffb8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## type?\n",
    "type(docs_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIovEIsVTsZ0",
    "outputId": "dff326b5-12cd-4e9c-cd6f-19365414187b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## length\n",
    "len(docs_holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_YH-0FMTxp_",
    "outputId": "785a7d49-982f-451e-f981-edaee7fff81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"txts downloadable\">\n",
      "<p class=\"pages\">Download this first set of text documents</p>\n",
      "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
      "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
      "</ul>\n",
      "**************\n",
      "<ul class=\"txts downloadable\">\n",
      "<p class=\"pages\">Download this second set of text documents</p>\n",
      "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
      "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
      "</ul>\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "## print to see each new one\n",
    "for section in docs_holder:\n",
    "  print(section)\n",
    "  print(\"**************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CODhezBzUNmy",
    "outputId": "80b7e1f7-7545-4da7-ef85-38b3a66069b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"txts downloadable\">\n",
      "<p class=\"pages\">Download this first set of text documents</p>\n",
      "<li>Text Document <a href=\"files/text_doc_01.txt\">1</a> </li>\n",
      "<li>Text Document <a href=\"files/text_doc_02.txt\">2</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_03.txt\">3</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_04.txt\">4</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_05.txt\">5</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_06.txt\">6</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_07.txt\">7</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_08.txt\">8</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_09.txt\">9</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_10.txt\">10</a></li>\n",
      "</ul>\n",
      "<ul class=\"txts downloadable\">\n",
      "<p class=\"pages\">Download this second set of text documents</p>\n",
      "<li>Text Document <a href=\"files/text_doc_A.txt\">1</a> </li>\n",
      "<li>Text Document <a href=\"files/text_doc_B.txt\">2</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_C.txt\">3</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_D.txt\">4</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_E.txt\">5</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_F.txt\">6</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_G.txt\">7</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_H.txt\">8</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_I.txt\">9</a></li>\n",
      "<li>Text Document <a href=\"files/text_doc_J.txt\">10</a></li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "## print a tags\n",
    "all_links = []\n",
    "for a_tag in docs_holder:\n",
    "  print(a_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_nizLI2VKVL",
    "outputId": "912c38ff-6252-446a-bb08-e30a80d5b59f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_02.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_03.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_04.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_05.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_06.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_07.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_08.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_09.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_10.txt\">10</a>],\n",
       " [<a href=\"files/text_doc_A.txt\">1</a>,\n",
       "  <a href=\"files/text_doc_B.txt\">2</a>,\n",
       "  <a href=\"files/text_doc_C.txt\">3</a>,\n",
       "  <a href=\"files/text_doc_D.txt\">4</a>,\n",
       "  <a href=\"files/text_doc_E.txt\">5</a>,\n",
       "  <a href=\"files/text_doc_F.txt\">6</a>,\n",
       "  <a href=\"files/text_doc_G.txt\">7</a>,\n",
       "  <a href=\"files/text_doc_H.txt\">8</a>,\n",
       "  <a href=\"files/text_doc_I.txt\">9</a>,\n",
       "  <a href=\"files/text_doc_J.txt\">10</a>]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## store in list\n",
    "all_a = [a_tag.find_all(\"a\") for a_tag in docs_holder]\n",
    "all_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQRkWVy6D45k"
   },
   "source": [
    "### flat is better than nested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZztguXaVub9",
    "outputId": "386a054e-255c-4d2c-b3aa-749038f56505"
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGQeldzsi_Dp"
   },
   "source": [
    "### We run into problems because we have a list of lists\n",
    "\n",
    "#### Quick detour to flatten list lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkYtIzr_i_Dq"
   },
   "source": [
    "## itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F729Ln8ci_Dq"
   },
   "outputs": [],
   "source": [
    "## let's use itertools to flatten the list\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKg_eOsOi_Dq",
    "outputId": "b831197c-a466-4391-ced0-1d02a5933fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"files/text_doc_01.txt\">1</a>,\n",
       " <a href=\"files/text_doc_02.txt\">2</a>,\n",
       " <a href=\"files/text_doc_03.txt\">3</a>,\n",
       " <a href=\"files/text_doc_04.txt\">4</a>,\n",
       " <a href=\"files/text_doc_05.txt\">5</a>,\n",
       " <a href=\"files/text_doc_06.txt\">6</a>,\n",
       " <a href=\"files/text_doc_07.txt\">7</a>,\n",
       " <a href=\"files/text_doc_08.txt\">8</a>,\n",
       " <a href=\"files/text_doc_09.txt\">9</a>,\n",
       " <a href=\"files/text_doc_10.txt\">10</a>,\n",
       " <a href=\"files/text_doc_A.txt\">1</a>,\n",
       " <a href=\"files/text_doc_B.txt\">2</a>,\n",
       " <a href=\"files/text_doc_C.txt\">3</a>,\n",
       " <a href=\"files/text_doc_D.txt\">4</a>,\n",
       " <a href=\"files/text_doc_E.txt\">5</a>,\n",
       " <a href=\"files/text_doc_F.txt\">6</a>,\n",
       " <a href=\"files/text_doc_G.txt\">7</a>,\n",
       " <a href=\"files/text_doc_H.txt\">8</a>,\n",
       " <a href=\"files/text_doc_I.txt\">9</a>,\n",
       " <a href=\"files/text_doc_J.txt\">10</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's blend BeautifulSoup and itertools\n",
    "target_a = list(itertools.chain(*all_a))\n",
    "target_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZH5X9IBi_Dr"
   },
   "source": [
    "## List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXBeF0ubi_Dr",
    "outputId": "a90d75ed-d09b-4c4e-d7ee-20bf5ce21762"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://sandeepmj.github.io/scrape-example-page/files/text_doc_01.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_02.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_03.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_04.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_05.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_06.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_07.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_08.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_09.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_10.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_A.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_B.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_C.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_D.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_E.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_F.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_G.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_H.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_I.txt',\n",
       " 'https://sandeepmj.github.io/scrape-example-page/files/text_doc_J.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1\n",
    "all_links = [base_url + atag.get(\"href\") for atag in target_a]\n",
    "all_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wjrnhrui_Dr"
   },
   "source": [
    "## Download all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "GXpDuRyvi_Dr",
    "outputId": "81f788e5-dc21-41a2-efd1-9c9505197b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading link 1 of 20\n",
      "100% [................................................................] 76 / 76Snoozing for 3 seconds before next link\n",
      "Downloading link 2 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 4 seconds before next link\n",
      "Downloading link 3 of 20\n",
      "100% [................................................................] 70 / 70Snoozing for 4 seconds before next link\n",
      "Downloading link 4 of 20\n",
      "100% [................................................................] 63 / 63Snoozing for 5 seconds before next link\n",
      "Downloading link 5 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 5 seconds before next link\n",
      "Downloading link 6 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 5 seconds before next link\n",
      "Downloading link 7 of 20\n",
      "100% [................................................................] 69 / 69Snoozing for 3 seconds before next link\n",
      "Downloading link 8 of 20\n",
      "100% [................................................................] 65 / 65Snoozing for 4 seconds before next link\n",
      "Downloading link 9 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 3 seconds before next link\n",
      "Downloading link 10 of 20\n",
      "100% [................................................................] 60 / 60Snoozing for 4 seconds before next link\n",
      "Downloading link 11 of 20\n",
      "100% [................................................................] 76 / 76Snoozing for 3 seconds before next link\n",
      "Downloading link 12 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 5 seconds before next link\n",
      "Downloading link 13 of 20\n",
      "100% [................................................................] 70 / 70Snoozing for 6 seconds before next link\n",
      "Downloading link 14 of 20\n",
      "100% [................................................................] 63 / 63Snoozing for 6 seconds before next link\n",
      "Downloading link 15 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 4 seconds before next link\n",
      "Downloading link 16 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 6 seconds before next link\n",
      "Downloading link 17 of 20\n",
      "100% [................................................................] 69 / 69Snoozing for 6 seconds before next link\n",
      "Downloading link 18 of 20\n",
      "100% [................................................................] 65 / 65Snoozing for 4 seconds before next link\n",
      "Downloading link 19 of 20\n",
      "100% [................................................................] 66 / 66Snoozing for 6 seconds before next link\n",
      "Downloading link 20 of 20\n",
      "100% [................................................................] 60 / 60Snoozing for 5 seconds before next link\n"
     ]
    }
   ],
   "source": [
    "## careful to put in a list name we just processed (via lc, fl, itertools)\n",
    "## download with timer\n",
    "links_total = len(all_links)\n",
    "link_count = 1\n",
    "\n",
    "for link in all_links:\n",
    "  print(f\"Downloading link {link_count} of {links_total}\")\n",
    "  link_count += 1\n",
    "  wget.download(link) ## non-colab notebook code\n",
    "#   files.download(wget.download(link)) ## this has files.download colab command\n",
    "  snoozer = randrange(3, 7)\n",
    "  print(f\"Snoozing for {snoozer} seconds before next link\")\n",
    "  time.sleep(snoozer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESg2snQNJS9I"
   },
   "outputs": [],
   "source": [
    "## glob\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zC_XOw7JVDK",
    "outputId": "b670906c-824a-4450-96f0-868d000925ab"
   },
   "outputs": [],
   "source": [
    "#put into list of only pdfs\n",
    "txt_files = glob.glob(\"*.txt\")\n",
    "txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AvBPwGmVJbO0",
    "outputId": "5790edb6-26e7-4ee1-cb9e-1cf73789cc10"
   },
   "outputs": [],
   "source": [
    "## download pdfs\n",
    "for txt_file in txt_files:\n",
    "  files.download(txt_file)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
